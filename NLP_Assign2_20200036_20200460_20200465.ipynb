{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5737caa2",
   "metadata": {},
   "source": [
    "# Ahmed Mohamed Ahemd 20200036 \n",
    "# Mohamed Abd ElGhaffar  20200460\n",
    "# Mohamed Essam Galal     20200465"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3762b6",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3615c",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cb0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6d8465",
   "metadata": {},
   "source": [
    "## Tokenization | Stemming | Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7cad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(preprocessed_words):\n",
    "    return nltk.word_tokenize(preprocessed_words)\n",
    "\n",
    "def stemming(word):\n",
    "    stemmer = PorterStemmer()\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "def lemmatizing(word):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb213258",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b598334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    preprocessed_text = re.sub(r'\\s+', ' ', text)                            # Remove All WhiteSpaces\n",
    "    preprocessed_text = re.sub(r'[^a-zA-Z0-9\\s]', '',preprocessed_text)      # Remove All Charchters Excepts Letters and Numbers\n",
    "    norm_preprocessed_text = preprocessed_text.lower()                       # Lower All Words \"Normalization\"\n",
    "    tokens = tokenize(norm_preprocessed_text)                                # Tokenizzing\n",
    "    \n",
    "    stop_words = stopwords.words('english')                                  # Stop-Words to be Removed\n",
    "    \n",
    "    stem_words = [stemming(word) for word in tokens if word not in stop_words] # Stemming\n",
    "    \n",
    "    lemmatize_words = [lemmatizing(word) for word in tokens if word not in stop_words] # Lemmatizing\n",
    "    \n",
    "    return lemmatize_words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e0b5b",
   "metadata": {},
   "source": [
    "## Getting Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049cd38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_words(stem_words = None, lemmatize_words = None):\n",
    "    try:\n",
    "        return set(lemmatize_words), set(stem_words)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5956c7",
   "metadata": {},
   "source": [
    "## Getting Categories \"Fields\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e1bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_categories(phrases):\n",
    "    brown_categories = [\n",
    "        'news',\n",
    "        'editorial',\n",
    "        'reviews',\n",
    "        'religion',\n",
    "        'hobbies',\n",
    "        'lore',\n",
    "        'belles_lettres',\n",
    "        'government',\n",
    "        'learned',\n",
    "        'fiction',\n",
    "        'mystery',\n",
    "        'science_fiction',\n",
    "        'adventure',\n",
    "        'romance',\n",
    "        'humor'\n",
    "    ]\n",
    "    \n",
    "    num_categories = min(phrases, len(brown_categories))\n",
    "    \n",
    "    random.shuffle(brown_categories)\n",
    "    \n",
    "    return brown_categories[:num_categories]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1601363",
   "metadata": {},
   "source": [
    "## Generate Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83549ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_documents(phrases):\n",
    "    categories = select_random_categories(phrases)\n",
    "    documents = []\n",
    "    for category in categories:\n",
    "        brown_corpus = brown.sents(categories=[category])\n",
    "        documents.append(' '.join(brown_corpus[1]))\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8476c2fc",
   "metadata": {},
   "source": [
    "## tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "835b12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac6aabe",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10467b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted .\",\n",
       " \"Just about the most enthralling real-life example of meeting cute is the Charles MacArthur-Helen Hayes saga : reputedly all he did was give her a handful of peanuts , but he said simultaneously , `` I wish they were emeralds '' .\",\n",
       " 'An interne , a nurse and two attendants were in charge of us .',\n",
       " 'Scotty did not go back to school .',\n",
       " 'It develops and analyzes the national income , balance of international payments , and many other business indicators .']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = generate_documents(5)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c1b94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x51 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 53 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f42c9f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "      atlanta: 0.2167\n",
      "      charge: 0.1748\n",
      "      city: 0.4333\n",
      "      committee: 0.2167\n",
      "      conducted: 0.2167\n",
      "      deserves: 0.2167\n",
      "      election: 0.4333\n",
      "      executive: 0.2167\n",
      "      jury: 0.2167\n",
      "      manner: 0.2167\n",
      "      overall: 0.2167\n",
      "      praise: 0.2167\n",
      "      presentment: 0.2167\n",
      "      said: 0.1748\n",
      "      termend: 0.2167\n",
      "      thanks: 0.2167\n",
      "\n",
      "Document 2:\n",
      "      charles: 0.2451\n",
      "      cute: 0.2451\n",
      "      emerald: 0.2451\n",
      "      enthralling: 0.2451\n",
      "      example: 0.2451\n",
      "      give: 0.2451\n",
      "      handful: 0.2451\n",
      "      hayes: 0.2451\n",
      "      macarthurhelen: 0.2451\n",
      "      meeting: 0.2451\n",
      "      peanut: 0.2451\n",
      "      reallife: 0.2451\n",
      "      reputedly: 0.2451\n",
      "      saga: 0.2451\n",
      "      said: 0.1977\n",
      "      simultaneously: 0.2451\n",
      "      wish: 0.2451\n",
      "\n",
      "Document 3:\n",
      "      attendant: 0.4207\n",
      "      charge: 0.3394\n",
      "      interne: 0.4207\n",
      "      nurse: 0.4207\n",
      "      two: 0.4207\n",
      "      u: 0.4207\n",
      "\n",
      "Document 4:\n",
      "      back: 0.5000\n",
      "      go: 0.5000\n",
      "      school: 0.5000\n",
      "      scotty: 0.5000\n",
      "\n",
      "Document 5:\n",
      "      analyzes: 0.3162\n",
      "      balance: 0.3162\n",
      "      business: 0.3162\n",
      "      develops: 0.3162\n",
      "      income: 0.3162\n",
      "      indicator: 0.3162\n",
      "      international: 0.3162\n",
      "      many: 0.3162\n",
      "      national: 0.3162\n",
      "      payment: 0.3162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for document in (documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    unique_words = tfidf_vectorizer.get_feature_names_out()\n",
    "    j = 0\n",
    "    for word in (unique_words):\n",
    "        tfidf = tfidf_matrix[i, j]\n",
    "        if tfidf > 0:\n",
    "            print(f\"      {word}: {tfidf:.4f}\")\n",
    "        j+=1\n",
    "    print(\"\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beeceb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76845a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5ab8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
